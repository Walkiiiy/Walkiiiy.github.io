
## 9.28
- token mimic SFT：
  - 避免模型在整体思路正确的情况下因为rules的微小错误导致sql推理错误
  - 输入的数据还是condensed_rules.json
  - 先用SFT的指定模型A进行rule inference
  - 拆解成一条条rule
  - 对于生成的每一条rule，和数据集中该数据的每一条rule进行embedding相似度计算
  - 取相似度最大且大于0.7的一条rule，让模型B在尝试在修改尽可能小的条件下，使rule1达到和rule2相同的效果，输出修改后的rule3
  - 如果所有相似度小于0.7，不进行任何操作
  - 将修改后的rule3替代rule1到第一轮输出的rules中，再进行一轮推理，并将修改后的rules作为lable对模型A进行微调并把loss调大
  - 

## 9.29

- 时间规划
  - 实验时间规划：
    - 目前训练的global assumer在其他开源text2sql模型上实验，已经取得效果
    - 10.8前实现自己的sql生成部分和local assumer
    - 实验已经证明核心方法有效，先把剩下的全实现了再优化ex
    - 10.15前做好初步实验
  - 论文时间规划：
    - 目前写了一点introduction和approach里的训练集rules合成方法
    - 10.8前写related works和approach的整体架构并画图
    - 10.20前完成第一版


- motivation和创新点
  - 针对**题目不够大**的问题，提出新的想法：
```markdown
  text2sql的输入natural language question(NLQ)**质量普遍太强**，与其初衷“使不了解schema结构和sql语句的普通用户也能执行查询”不符
  
  我们**对传统NLQ输入进行弱化**，与**普通用户场景**下能达到的输入质量对齐：
    对与Bird数据集，不输入evidence
    并且对Bird和Spider的NLQ进行模糊处理
  在此输入下，对已有的text2sql方法进行测试，ex大大降低，这证实了我们的观点

  为此我们提出了**在弱NLQ输入条件下仍能高质量生成SQL**的方法: **rules-assuming** structure
  ....
```
- rules ex优化想法
- 横向问题

- 共一
- 细致计划：到天，到图，到实验
- no fake work，实验进度最重要
- 先别管论文只管实验



