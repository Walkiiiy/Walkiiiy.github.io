### 5.18
- EmoAnalyze
    - 跑通已有的torch SFT脚本（感谢昊达哥大力相助
    - LLM的SFT有不少封装库，自己写了调用trl库封装实现的SFT并跑通。
    - 自己写纯torch的SFT调参有点弄不明白，交叉熵loss最低才能降到2.1。打算看看吴恩达的SFT调参再自己写出来
- LLM
    - 学习总结纯解码器的LLM：
    https://walkiiiy.github.io/2025/05/15/GPT-styleLLMstructure/
    -  下一步打算看多模态相关文献
- topic
    - 阅读文献**Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study**
       - prompt方案，直接将表格序列化输入。同时提出了LLM对Table的分析能力的测试方法，但没有改进模型结构也没有对模型进行微调(分析正确率也普遍低)
       - 提出自增强提示Self-Augmented Prompting，先用LLM识别表格特定范围，类型，座标等信息（这一步是模板化提问），结果信息再加入到第二次prompt，能提高推理准确性
    - 下周打算读完TablePilot 