### 6.1
- **LLM**
  - 学习两种MLLM的实现方法以及图像模态的VIT和Clip编码器
    - 笔记在https://walkiiiy.github.io/2025/05/29/Multimodal-LLMs/
- **topic**
    - 阅读文献**WizardLM: Empowering Large Language Models to Follow Complex Instructions**
       - 论文的核心方法Evol-Instruct在ChatTS中被使用，想到可以用来生成table相关的细粒度query，给将这篇源论文补一篇报告
       - 通过指令演化生成大规模复杂指令数据集，对模型进行监督微调。使用GPT做进化引擎，构建prompt模板，随机选择 “深度进化”或“广度进化”来将简单指令升级为更复杂的指令或创建新指令以增加多样性。
       - 笔记在https://walkiiiy.github.io/2025/05/30/WizardLM-evol-instruct/
    - **Ideas:**
      - 目前想到的实际上就是要做一个能提问的TablePilot，让他结合提问分析Table，而不是只靠table盲目生成分析报告。
      - table指令相关数据集可以使用tableLlama的table-Instruct,但是缺少使用代码查表绘图来分析数据的问答。
      - TablePilot提供了一种很好的根据表格衍生代码型任务问答的思路，可以用于生成高质量Tabular**代码**问答数据。
      - ChatTS在数据准备模块，改进Evol-Instruct为TSEvol，该策略适合由一个根提问衍生出许多高质量的**语言**问答，也可以用于生成细粒度query。
      - 结合指令演化Evol-Instruct，生成细粒度query，同时将其作为训练数据集构建和实际使用时的细粒度query生成方法。
    - **ToBeDealt：**
        - 以什么形式输入Table？
          - 首先不能纯文本全部输入（2022的tableLlama就是）会损失数据精度和上下文理解。 
          - 如果Table数据单独作为一种模态，采用哪种多模态处理方法？用跨注意力还是编码器统一嵌入？（有创新性但不能保证效果，需要进一步调研）
          - 倾向于采用TableMaster/TablePilot的方法：子集采样、生成解释和依赖关系，使用代码查询子query（这个好像更简单更可行）
        - **各细粒度query的回答如何整合？**（TablePilot的ranking也许可以提供思路）