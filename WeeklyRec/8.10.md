## 8.4
- document获取两种思路：deepresearch或者agentic ragflow
- samples of needing to understand all values:
```JSON
  - finicial.csv
  -         "column8": {
            "originColumnName": "bank",
            "fullColumnName": "bank of the partner",
            "dataFormat": "text",
            "valueDescription": "each bank has unique two-letter code",
            "size": 1056320,
            "emptyValueCount": 782812,
            "valType": "discrete",
            "typeNum": 13,
            "samples": [
                "OP",
                "YZ",
                "WX",
                "CD",
                "KL",
                "ST",
                "IJ",
                "QR",
                "UV",
                "GH"
            ]
        },       
  - student_club.csv
  -         "column5": {
            "originColumnName": "short_state",
            "fullColumnName": "short state",
            "columnDescription": "The abbreviation of the state to which the ZIP pertains",
            "dataFormat": "text",
            "size": 41877,
            "emptyValueCount": 0,
            "valType": "discrete",
            "typeNum": 52,
            "samples": [
                "ME",
                "LA",
                "TN",
                "OK",
                "VA",
                "KS",
                "MO",
                "OH",
                "NE",
                "MT"
            ]
        }
  - thrombosis_prediction.csv      
  -         "column6": {
            "originColumnName": "Diagnosis",
            "columnDescription": "disease names",
            "dataFormat": "text",
            "size": 1238,
            "emptyValueCount": 1,
            "valType": "discrete",
            "typeNum": 219,
            "samples": [
                "Hypergammmaglobulinemia",
                "MCTD susp",
                "autoimmune leukopenia",
                "SLE, APS susp",
                "SJS, MCTD, AORTITIS",
                "infectious  mononucleosis",
                "PSS, UC",
                "PM, PSS, SJS",
                "RA (seronegative)",
                "RA(seronegative)"
            ]
        }
  -         "column5": {
            "originColumnName": "ANA Pattern",
            "fullColumnName": "pattern observed in the sheet of ANA examination",
            "columnDescription": "pattern observed in the sheet of ANA examination",
            "dataFormat": "text",
            "size": 806,
            "emptyValueCount": 261,
            "valType": "discrete",
            "typeNum": 15,
            "samples": [
                "P.D",
                "D,P,S",
                "S,P",
                "S,D",
                "P.S",
                "D,P",
                "P,S",
                "S,N",
                "S",
                "p"
            ]
        },
  - 
```
- arc_refine:
    - clean数据集document包含所有column的正确详细介绍，背景文档，可以打散混在脏数据中，
    - dirty数据集一个正确解释混在可能的错误解释中，而且可以考虑有的不要正确解释
    - contribution:
    - dataset(clean),dataset(dirty) 
    - assumption agentic tool
    - Parser-Planner-Generator arc
    - parser可以以dirty作为输入，clean 作为输出，其中assumer tool对于每一个模糊值（abbrevation,obscure terms）先做assumption query，再调dirty对assumption query做验证和筛选，返回给parser产生最终结果（也是所有column的详细介绍）与clean做匹配。
- clean_document_gather_refine:
```python

def getDocument(keyWord:Metadata):
    res_doc=''
    ##getting description
    if keyWord.ambiguous():
        keyWord.schema+=web_search(keyWord.schema)
    res_doc+=keyWord.NLdescription()
    ## getting background
    queries=getBackgroundQueries(keyWord.schema)
    for query in queries:
        keyWord.background+=websearch(query)       
    res_doc+=keyWord.background
    return res_doc
    
def processTable(table:metadata):
    col_documents=[]
    for column in table:
        col_document={}
        col_document['document']=getDocument(column)
        if column.valType=="discrete":
            col_document['values']=[]
            for val in column:
                col_document['values'].append(getDocument(val))
        col_documents.append(col_document)

    table_document={}
    table_document['document']=getDocument(table)
    table_document['column_documents']=col_documents
    return table_document

database_document={}
database_document['document']=getDocument(database)
database_document['table_documents']=[]
for table in database:
    database_document['table_documents'].append(processTable(table))

```


## 8.5
- 新思路(V8)：直接把query加入到生成prompt，通过搜索evidence平替文档，根据提示获取clean document
  - GPT:时间从40min-1h不等，输出格式合适，会输出有价值的链接文档，但是有时输出的链接文档过于简单，需要人工筛选。
  - manus：垃圾
## 8.6
- 否定）改进：可以只考虑困难难度的文档。
- 改进：可以将query一个一个输入模型试试
- 读bird original paper
- **面向query生成文档流程**：
  - 执行：输入query和schema，无evidence，让deepseek执行，执行失败的划入失败集
  - 输入query和schema和sql和gold_sql(和evidence,对于有evidence的数据集)，对失败集的query进行失败原因分析，原因1，原因2，原因3......
  - 如果原因分析中，加入外部说明文档有可能改进：划入搜索集
  - 搜索：当搜索集非空时，对搜索集进行搜索：根据query和evidence，找evidence的平替document
  - 搜索完毕后再次执行，执行成功放入文档集，失败放入搜索集循环改进（k-top后还失败就人工生成文档
- 先正一个执行脚本
- **2sql失败原因：**
  - 缺少背景知识了解（可能是schema或者query的重要背景
  - 缺少对表的了解：
    - Question: Which students manage to generate the highest income. State his/her name along with the income source.
        ```sql
        SELECT T1.first_name, T1.last_name, T2.source  
        FROM member AS T1  
        INNER JOIN income AS T2 ON T1.member_id = T2.link_to_member  
        WHERE T2.amount = (  
            SELECT MAX(amount)  
            FROM income  
        )  
        ORDER BY T2.amount DESC
        ```
    - it leads to a NULL result set since MAX(amount) is 3000 in the orignal table income. 
        However, the ground-truth SQL should consider the MAX(amount) in the joined table pertaining 
        to tables member and income. Therefore, the largest amount is only 50, and the ground-truth 
        SQL should be:
        ```sql
        SELECT T1.first_name, T1.last_name, T2.source
        FROM member AS T1
        INNER JOIN income AS T2
        ON T1.member_id = T2.link_to_member
        WHERE T2.amount = (
            SELECT MAX(T4.amount)
            FROM member AS T3
            INNER JOIN income AS T4
            ON T3.member_id = T4.link_to_member
            )
        ```
  - question本身模糊，理解角度多样
## 8.7
- 三种错误的处理方法：
  - 缺少背景知识：返回query,依据关键词查找外部文档
  - 缺少表的理解：指出schema缺陷
  - question本身模糊：结合gold_sql返回清晰的question
- 写错误处理轮
- how BIRD dataset divide the difficulty level?
  - if it's not based on statistics, should we use mutiple runs of excute?
- 似乎web-search背景文档没有想象中的多或者被需要，如果测数结果很少的画就不用agent了，直接手工搜索
- **反向思路：**
  - 对比sql和gold_sql找evidence，一直循环测试，添加evidence，循环直到evidence足够产生正确答案为止。
  - 所有question的evidence作为文档
  - 这个evidence分三类，也就是三类错误原因：生词解释，schema补充，question澄清
  - 由此可以得到正确率极高的evidence（文档）+question数据集,然后后续思路做减法，这正能支持assumer-verifier的训练
  - 最终输入的文档中可能含有错evidence，缺失evidence，而模型要具有较强的evidence推理、筛选能力
- "with no explanation" 可以提升准确率，但是在这里不能用，因为需要思路步骤来保证后续evidence生成可追溯
- 三种错误中有一种是分支情况，就是question本身模糊有歧义。这种可以考虑并行执行 
- 训练Assumer时可以只输入question和schema，把全部的evidence和answer做为label，也可以把部分evidence一起输入，让他推理补全evidence并回答answer，因为领域相近，相似的数据库之间，特别是同一个数据库evidence之间一定含有相似性
- 思路验证两部：
  - 找到本身无法解答的question
  - 给GPT推理evidence，直到可以解答
- 跑一轮dev四块整
## 8.10
- 百分百正确提示的文档合成，面向schema的话即使都用gpt5-agent处理都不太行，现在正在试面向question合成
- 思路：
    - 对比sql和gold_sql找evidence，一直循环测试，添加evidence，循环直到evidence足够产生正确答案为止。
    - 执行：
      - 输入query和schema，无evidence，deepseek输出reason和sql，执行失败的划入失败集
      - refine：输入query，schema，sql，reason和gold_sql（正确答案），对失败集的sql进行失败原因分析，生成evidence
      - 三种错误及其处理方法，对应三类evidenve：
        - 缺少背景知识(背景补充)：背景知识补全，或返回query,依据关键词查找外部文档
        - 缺少表的理解（解释schema）：指出schema缺陷，没有描述完整或需要特别注意的地方
        - 输入的question本身模糊（澄清question）：结合gold_sql返回描述清晰的question
      - eval:输入refine后的evidence集和question、schema,若答案正确移出失败集
      - looping：当失败集非空时，循环执行refine和eval
      - k次后还失败就划为特殊，由人工生成文档 
    - 所有question的evidence作为文档
- 由gpt实测可以得到正确率极高的evidence（文档）+question数据集,后续思路做减法，支持assumer-verifier的训练
- 虽然不少文献都说“with no explanation”可以增加ex，但实测在循环改进情景下输入之前的reasoning可以减少轮数。
- 只要是tabular-query数据集都可以拿来跑，目前跑了一轮bird-dev1500个question
- 目前的问题：
  - deepseek输出的evidence太突出对比之前的sql错误，输出的evidence相比与文档，更像是纠错报告的感觉，目前想通过优化prompt改进
- 下周计划：
  - 优化prompt，优化文档，尽量让他简略一些同时保证正确率
  - 查到的和这个思路有相似之处的研究有self-refine和seal，下周读一下论文