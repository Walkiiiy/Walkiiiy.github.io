### 7.20

- 7.15
  - 理解schema
  - 生成质量与多样性
- 7.16
  - xiyan experiment: 
    - compares the results of a predicted SQL query and a reference SQL query executed on a specific database instance.
    - training materials from combined spider, Bird, SQL-EVAL, NL2GQL
  - dataset synthesis:
    - reference:
      - bird: los of human resources used. manully annotation and examination.
      - 
    - Basic route:
      - use deepseek v3 or finetuned model?
      - first construct a schema format of the database, the idea of profiling process in Bird_top1 can be used, this step can also use LLM for observation and conclusion. for example:
        schema
        - tablename
          - 
          - columnname
            - description
            - statistics
            <!-- !-- -  minihash -- -->
            - exampl evalus
            - measurement
            - format(might Be Different)
            - relation With Other Columns
            - relation with this lable
            - relation with the database
      - Agent1 analyze all the description csv and the tables in the database, give a guess about the main idea of the table/column/database and do the sreach
      - Agen2 select(rate) all the search res returned by Agent1, taken top_k, merge them into one specific document.(relevence looping strategy like Bird_top1 could be used here)
      - manully examine the document, see if it is relevant to the table, and if its helpful for LLM's understanding. 
- 7.17
  - record Database name info
  - long value trunction
  - nan value stastic, taking example from non-Nan value.
-----------------------------------------------------------------
  - make a description of statistics:
    - pass
  - **for a value, determain wether do the search or not**:
    - the column can be devided by its values as descrete ones and continuous ones.
      -  do quick hash for every value(e.g. python set), denote S as set length, denote L column length(dropNa), denote T as a threshold, if S/L>T, its a descrete type column. To avoid dirty value like PC,pc,personal computer, LSH and word-embedding similirty coud be used.
      -  if obscure, add the set to schema's column example.
    - the obscure can happen both in column name and in value,for obscure in value:
      - if the column type is **descrete**
      - **hard to understand**(shot name, unknown area), cant get its Purpose
      - do the search
  
  - procedure doing the search of a certain keyword:
    - Agent based search, tools api revoke required.
    - only by the key-word itself can could be hard to find, use a set of key-words and a main key-word, use different combination to do the search.(e.g. IRC it self cant get Intervention Resource Classroom)
    - references needed.

  - rate and extract top_k information from search report to a doc:
    - pass

  - link the doc to the schema,database synthesized.

----------------
p.s:
  - for a huge paramater LLM, a short description could be understood, while for a smaller LLM, short description itself might be a challenge.
  - define a decument as a NL description of the background of the database's grand background, or the background of its certain table, column, or value. As long as a place-holder is hard to understand, obscure, strange to LLM, get a doc from Internet.
  - note that wiki search to be added tomorrow.


### 7.20
- 补充Bird_top5 
  - 阿里云的XiYan-SQL：A PREVIEW OF XIYAN-SQL: A MULTI-GENERATOR ENSEMBLE FRAMEWORK FOR TEXT-TO-SQL
  - top_1,2的方法使用4-o，gemini这样的大模型，只进行few-shot prompt,而XIYAN-SQL使用参数量相对较小的32B千问模型进行SFT和prompt，
  也能达到相当的效果（但训练量大，使用四个与Bird同等级的NL2SQL训练集微调）该方法在考虑训练成本和query生成速度的综合排名中占第一。
  - 笔记在https://walkiiiy.github.io/2025/07/15/XiYan-SQL/
- NL2SQL方法总结
  - top_rank方法都可总结为三部：
    - schema describe:描述schema(meta-data)，description过于简单会使LLM无法理解表的结构，过于详细又会使上下文过长，影响推理效果。
    - schema linking：通过embedding相似度和局部敏感哈系LSH提取表中与问题相关的列，只将相关列的schema送入generator做query生成，保证最佳上下文长度和理解效果。
    - candidate generate/selection: 根据schema和用户问题生成可执行的query。selection又分为简单的语义、执行率纠错(2,5)和query相关度(1)提升，都用k轮循环改进实现。
  - top3,4没有公开论文，1，2，5的方法结构都遵从以上三部，其中2，5专注于generator，前两部的schema描述方法比较传统。top_1对描述方法、相关度进行改进，
  generator反而没有做很多文章。这可以看作消融实验，说明加强模型对表的理解比改进模型query生成能力更重要，研究每个表配备背景文档的思路可以从这里入手。
  - 杨博说数据集可以在Bird基础上构建，给每个表找背景文档。NL2SQL太卷，不做sql，要结合Agent，针对表格文档的数据分析。
- 数据集表格背景文档补全
  - 弄了Bird全部表的schema：
  - ![schema_example](schema_example.png)
- 下周计划：
  - 想先找agent informtion retrieval相关的论文，看能不能和背景文档搜集结合
  - 设计完整文档搜集流程