### 7.20

- 7.15
  - 理解schema
  - 生成质量与多样性
- 7.16
  - xiyan experiment: 
    - compares the results of a predicted SQL query and a reference SQL query executed on a specific database instance.
    - training materials from combined spider, Bird, SQL-EVAL, NL2GQL
  - dataset synthesis:
    - reference:
      - bird: los of human resources used. manully annotation and examination.
      - 
    - Basic route:
      - use deepseek v3 or finetuned model?
      - first construct a schema format of the database, the idea of profiling process in Bird_top1 can be used, this step can also use LLM for observation and conclusion. for example:
        schema
        - tablename
          - 
          - columnname
            - description
            - statistics
            <!-- !-- -  minihash -- -->
            - exampl evalus
            - measurement
            - format(might Be Different)
            - relation With Other Columns
            - relation with this lable
            - relation with the database
      - Agent1 analyze all the description csv and the tables in the database, give a guess about the main idea of the table/column/database and do the sreach
      - Agen2 select(rate) all the search res returned by Agent1, taken top_k, merge them into one specific document.(relevence looping strategy like Bird_top1 could be used here)
      - manully examine the document, see if it is relevant to the table, and if its helpful for LLM's understanding. 
- 7.17
  - record Database name info
  - long value trunction
  - nan value stastic, taking example from non-Nan value.
-----------------------------------------------------------------
  - make a description of statistics:
    - pass
  - **for a value, determain wether do the search or not**:
    - the column can be devided by its values as descrete ones and continuous ones.
      -  do quick hash for every value(e.g. python set), denote S as set length, denote L column length(dropNa), denote T as a threshold, if S/L>T, its a descrete type column. To avoid dirty value like PC,pc,personal computer, LSH and word-embedding similirty coud be used.
      -  if obscure, add the set to schema's column example.
    - the obscure can happen both in column name and in value,for obscure in value:
      - if the column type is **descrete**
      - **hard to understand**(shot name, unknown area), cant get its Purpose
      - do the search
  
  - procedure doing the search of a certain keyword:
    - Agent based search, tools api revoke required.
    - only by the key-word itself can could be hard to find, use a set of key-words and a main key-word, use different combination to do the search.(e.g. IRC it self cant get Intervention Resource Classroom)
    - references needed.

  - rate and extract top_k information from search report to a doc:
    - pass

  - link the doc to the schema,database synthesized.

----------------
p.s:
  - for a huge paramater LLM, a short description could be understood, while for a smaller LLM, short description itself might be a challenge.
  - define a decument as a NL description of the background of the database's grand background, or the background of its certain table, column, or value. As long as a place-holder is hard to understand, obscure, strange to LLM, get a doc from Internet.
  - note that wiki search to be added tomorrow.