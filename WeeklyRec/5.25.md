### 5.25
- **EmoAnalyze**
    - 完善了训练脚本，弄清参数细节作用以及之前错误的原因：
      - 主要是因为tokenizer部分没写好
    - 对比了一下pythia-70m，pythia-140m，Llama3-8b模型，使用和不用Lora的训练效果：
      - 前两个小模型能在CPU跑，但是只会提取关键词，只要评论带good就算positive。Llama3-8b一上来的loss就比前两个小模型的最终loss还低，训练20000步loss就基本为0了）
- **topic**
    - 阅读文献**TablePilot: Recommending Human-Preferred Tabular Data Analysiswith Large Language Models**
       - 给定表格，大模型自动分析表格背景信息、依赖关系等。从数据提取、可视化、建模分析三个角度生成任务，生成对应代码和结果并对任务价值进行排序，输出最具有分析价值的Top K作为报告。
       - 由于他是自问自答来生成报告的，不支持动态分析提问，我感觉他对于用户来说价值不大。但是他针对给定表格，生成优化出有价值的问答数据并排序的策略非常好，也许适合拿来作为研究TabularLLM的一个数据集生成策略？
       - 详细笔记在https://walkiiiy.github.io/2025/05/25/TablePilot/