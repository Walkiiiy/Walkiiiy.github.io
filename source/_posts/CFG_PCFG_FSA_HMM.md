---
title: CFG_PCFG_FSA_HMM
date: 2025-03-20 10:07:08
tags:
---
## CFG上下文无关法（乔姆斯基范式）
### **前置定义：**
**非终结符**（Non-terminal symbols，N）：可以继续展开的符号，比如：
* S（表示句子 Sentence）
* NP（名词短语 Noun Phrase）
* VP（动词短语 Verb Phrase）
  
**终结符**（Terminal symbols，Σ）：不能再展开的符号，比如：
"小明"、"吃了"、"苹果"（这些都是具体的词）

**规则**（Production Rules，R）：定义如何展开非终结符，比如：
```
S  → NP VP  （句子由 名词短语 + 动词短语 组成）
NP → "小明" | "这只猫" | "那个老师"  （名词短语可以是具体的词）
VP → "吃了苹果" | "跑得很快" | "在看电视" （动词短语可以是具体的动词结构）
```
**起始符号**（Start Symbol，S）：表示整个句子的起点，比如 S。
### 应用:
用：
S → NP VP
NP → "小明"
VP → "吃了苹果"
生成“小明吃了苹果”这样的范式就是CFG上下文无关法（乔姆斯基范式）

## 概率上下文无关文法（PCFG）
在CFG句法树的基础上，每条规则都有一个概率，表示这条规则被选中的可能性。
```
S  → NP VP   (1.0)
NP → "小明" (0.5) | "这只猫" (0.5)
VP → "吃了苹果" (0.7) | "跑得很快" (0.3)
```
生成“这只猫跑的很快”的概率为1.0 × 0.5 × 0.3 = 0.15。
## 正则文法(有限状态自动机FSA)
### **前置定义：**
一个 正则文法 是一个四元组G=(N,Σ,R,S)，其中：
* N：非终结符（Non-terminal symbols），如 S, A, B。
* Σ：终结符（Terminal symbols），比如 "a", "b", "0", "1"。
* R：规则（Productions），具有以下形式：
```
A → aB
A → a
```
### **应用：**
假设有
```
S → aA
A → bB
B → c
```
则可展开：
```
S → aA
   → a bB
   → a b c
```
且可转化为正则表达式：
**S → aS | bS | ε** 等价于 **(a|b)***

## 隐马尔科夫模型（HMM）
隐马尔科夫模型（HMM）是一种**概率模型**，用于描述一个具有**隐含状态**的马尔科夫过程。HMM 适用于时间序列数据，能够用于解决状态不可直接观测、但可以通过观察某些变量间接推测的情况。

HMM 主要由**隐藏的状态序列**和**可观察的输出序列**两部分组成：
- **隐藏状态（Hidden States）**：系统的真实状态，不能直接被观察（例如：天气是晴天、雨天、雪天）。
- **观察序列（Observations）**：我们能观测到的变量，由隐藏状态决定（例如：某人每天是否携带雨伞）。
- **状态转移**：HMM 假设系统会在隐藏状态之间按照**马尔科夫过程**进行转移，即下一个状态只依赖于当前状态，而与更早的状态无关。

---

#### **2. HMM 的基本组成**
一个完整的 HMM 由以下五个部分（参数）定义：

1. **状态集合（Hidden States）**：
   - 设隐藏状态集合为 $ S = \{S_1, S_2, ..., S_N\} $，其中 $ N $ 是隐藏状态的数量。
   
2. **观察集合（Observations）**：
   - 设可观察的符号集合为 $ O = \{o_1, o_2, ..., o_M\} $，其中 $ M $ 是观察到的不同符号的数量。

3. **初始状态分布（Initial State Probability）**：
   - 记作 $ \pi = \{\pi_i\} $，其中 $ \pi_i = P(S_1 = S_i) $ 表示初始时刻处于状态 $ S_i $ 的概率。

4. **状态转移矩阵（State Transition Probability）**：
   - 记作 $ A = \{a_{ij}\} $，其中：
     $$
     a_{ij} = P(S_{t+1} = S_j \mid S_t = S_i)
     $$
     表示当前状态为 $ S_i $ 时，下一时刻转移到状态 $ S_j $ 的概率。

5. **观察概率矩阵（Observation Probability）**：
   - 记作 $ B = \{b_j(o_k)\} $，其中：
     $$
     b_j(o_k) = P(O_t = o_k \mid S_t = S_j)
     $$
     表示在状态 $ S_j $ 下，观测到符号 $ o_k $ 的概率。

> **完整的 HMM 模型**可以表示为 $ \lambda = (A, B, \pi) $。

---
### **HMM 的三大问题**

---

### **(1) 评估问题（Forward-Backward Algorithm）**

#### **问题描述**
给定一个观察序列 $ O = (o_1, o_2, ..., o_T) $，以及已知的隐马尔科夫模型参数 $ \lambda = (A, B, \pi) $，**评估问题**的目标是计算该观察序列的概率：
$$
P(O \mid \lambda)
$$
也就是说，给定模型参数和观察到的序列，计算这个观察序列的发生概率。

#### **简单计算是不可行的**
如果我们尝试直接计算 $ P(O \mid \lambda) $，我们需要考虑所有可能的**隐藏状态序列**。因为对于每个时刻 $ t $，隐藏状态 $ S_t $ 可能有 $ N $ 种选择（假设有 $ N $ 个隐藏状态），所以状态序列的总数会是 $ N^T $（T 是观察序列的长度）。这种计算量随着序列长度 $ T $ 增长会迅速变得非常庞大，难以计算。

#### **前向算法（Forward Algorithm）**
为了高效解决这个问题，**前向算法**通过递归方法计算每个时刻的概率，避免了暴力枚举所有状态序列。

1. **初始化：**  
   对于第一个观察值 $ O_1 $，我们可以直接用初始状态概率和观察概率来计算前向概率：
   $$
   \alpha_1(i) = \pi_i \cdot b_i(o_1)
   $$
   其中 $ \alpha_1(i) $ 表示在时刻 $ t = 1 $，假设当前隐藏状态是 $ S_i $，并且观测到 $ O_1 $ 的概率。 $ \pi_i $ 是初始状态的概率， $ b_i(o_1) $ 是状态 $ S_i $ 产生 $ o_1 $ 的概率。

2. **递推：**  
   对于后续的观察值 $ O_2, O_3, ..., O_T $，我们递归地计算每个时刻的前向概率。假设在时刻 $ t $ 时状态为 $ S_i $，那么：
   $$
   \alpha_{t+1}(j) = \left( \sum_{i=1}^{N} \alpha_t(i) \cdot a_{ij} \right) \cdot b_j(o_{t+1})
   $$
   这表示我们通过前一时刻所有可能的状态 $ S_i $，计算在当前状态 $ S_j $ 下观察到 $ O_{t+1} $ 的概率。这里 $ a_{ij} $ 是状态转移的概率， $ b_j(o_{t+1}) $ 是当前状态 $ S_j $ 观察到 $ o_{t+1} $ 的概率。

3. **终止：**  
   最终，计算所有时刻 $ T $ 的前向概率并求和得到总概率：
   $$
   P(O \mid \lambda) = \sum_{i=1}^{N} \alpha_T(i)
   $$
   其中 $ \alpha_T(i) $ 表示在时刻 $ T $ 时处于状态 $ S_i $ 的前向概率。

#### **计算复杂度**
前向算法的时间复杂度为 $ O(N^2 T) $，这是因为我们在每个时刻 $ t $ 都需要计算 $ N $ 个状态的前向概率，每次计算时需要遍历所有 $ N $ 个可能的前一时刻状态。

---

### **(2) 解码问题（Viterbi Algorithm）**

#### **问题描述**
给定观察序列 $ O = (o_1, o_2, ..., o_T) $ 和 HMM 模型参数 $ \lambda = (A, B, \pi) $，**解码问题**的目标是找出**最可能的**隐藏状态序列 $ S^* = (S_1^*, S_2^*, ..., S_T^*) $，即给定观察到的序列，推断出最有可能的隐状态序列。

#### **朴素解法：**
直接计算所有状态序列的概率并找到最大值。显然，这个方法复杂度是指数级的，随着序列长度 $ T $ 和状态数量 $ N $ 增加，计算量非常庞大。

#### **维特比算法（Viterbi Algorithm）**
为了解决这个问题，维特比算法使用**动态规划**，通过递归地计算最优路径，避免了枚举所有可能的状态序列。

1. **初始化：**  
   对于第一个观察值 $ O_1 $，我们直接用初始状态概率和观察概率计算最优路径的概率：
   $$
   \delta_1(i) = \pi_i \cdot b_i(o_1)
   $$
   其中 $ \delta_1(i) $ 表示在时刻 $ t = 1 $，假设当前状态是 $ S_i $，并且观察到 $ O_1 $ 的最优概率。

2. **递推：**  
   对于后续的观察值 $ O_2, O_3, ..., O_T $，我们递归地计算每个时刻最优路径的概率：
   $$
   \delta_{t+1}(j) = \max_{i} \left[ \delta_t(i) \cdot a_{ij} \right] \cdot b_j(o_{t+1})
   $$
   这表示我们通过前一时刻所有可能的状态 $ S_i $，计算在当前状态 $ S_j $ 下观察到 $ O_{t+1} $ 的最优概率。

3. **回溯：**  
   一旦计算到最后一个时刻 $ T $，我们就可以回溯找到最优路径：
   $$
   S^*_T = \arg \max_i \delta_T(i)
   $$
   然后我们从 $ T $ 时刻开始，回溯到 $ t = 1 $，通过记录每个时刻的最优状态。

#### **计算复杂度**
维特比算法的时间复杂度为 $ O(N^2 T) $，和前向算法类似，但它同时也记录了每个时刻的最优路径，可以通过回溯得到最优状态序列。

#### **HMM评价**
**适用于序列数据**：HMM 是建模时间序列的强大工具。
**可解释性强**：HMM 的状态转移和观察概率能够直观解释数据生成过
**无法捕捉长期依赖**：HMM 仅考虑当前状态和下一个状态，而无法建模更长时间跨度的依赖关系（相比 LSTM、Transformer）。

---

